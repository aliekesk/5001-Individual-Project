{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data_2 = pd.read_csv('train_2.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train_data,train_data_2,test_data],axis = 0).reset_index()\n",
    "data.drop(['index','id'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1(alpha,ratio,penalty):\n",
    "    if penalty == 'l1':\n",
    "        return(alpha)\n",
    "    elif penalty == 'elasticnet':\n",
    "        return(alpha * ratio)\n",
    "    else:\n",
    "        return(0)\n",
    "    \n",
    "def l2(alpha,ratio,penalty):\n",
    "    if penalty == 'l2':\n",
    "        return(alpha)\n",
    "    elif penalty == 'elasticnet':\n",
    "        return(alpha * (1-ratio))\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['l1'] = data.apply(lambda row: l1(row['alpha'],row['l1_ratio'],row['penalty']),axis = 1)\n",
    "data['l2'] = data.apply(lambda row: l2(row['alpha'],row['l1_ratio'],row['penalty']),axis = 1)\n",
    "data['n_clusters'] = data['n_classes'] * data['n_clusters_per_class']\n",
    "data['num'] = data['n_samples'] * data['n_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_job(x):\n",
    "    if x == -1:\n",
    "        return(16)\n",
    "    else:\n",
    "        return(x)\n",
    "def rep_ratio(ratio,penalty):\n",
    "    if penalty == 'elasticnet':\n",
    "        return(ratio)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "def rep_alpha(alpha,penalty):\n",
    "    if penalty == 'none':\n",
    "        return(0)\n",
    "    else:\n",
    "        return(alpha)\n",
    "\n",
    "data['l1_ratio'] = data.apply(lambda row:rep_ratio(row['l1_ratio'],row['penalty']),axis = 1)\n",
    "data['alpha'] = data.apply(lambda row: rep_alpha(row['alpha'],row['penalty']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['efficiency'] = data['max_iter'] / data['n_jobs']\n",
    "data['complexity'] = data['num'] * data['max_iter']\n",
    "data['local'] = data['n_samples'] * data['max_iter']\n",
    "data['num*iter_job'] = data['num'] * data['max_iter'] / data['n_jobs']\n",
    "data['num_class*flip*iter'] = data['num']/data['n_classes'] * data['flip_y'] * data['max_iter']\n",
    "data['num_class*flip*iter'] = data['num']/data['n_classes'] * data['flip_y'] * data['max_iter']\n",
    "data['feature * iter'] = data['n_features'] * data['max_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:440]\n",
    "test = data[-len(test_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = train[train['time'] >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(dataframe,count):  \n",
    "    n = len(dataframe)\n",
    "    num_list = []\n",
    "    init_num = np.random.randint(0,n,1)\n",
    "    num_list.append(int(init_num[0]))\n",
    "    df = pd.DataFrame(data.loc[init_num])\n",
    "    for i in range(count - 1):\n",
    "        num = np.random.randint(0,n,1)\n",
    "        num_list.append(int(num[0]))\n",
    "        new_df = pd.DataFrame(data.loc[num])\n",
    "        df = pd.concat([df,new_df], axis = 0)\n",
    "    return df, num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "large2,numlist = bootstrap(large,100)\n",
    "train = pd.concat([train,large],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffle(train)\n",
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train,test],axis =0)\n",
    "data['time'] = data['time'].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in data.columns:\n",
    "    if feature != 'time'and feature != 'penalty_elasticnet'and feature != 'penalty_l1' and feature != 'penalty_l2' and feature != 'penalty_none':\n",
    "        data[feature] = (data[feature] - data[feature].mean())/data[feature].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:400]\n",
    "test = data[400:469]\n",
    "train_X = train[[ 'flip_y', 'max_iter', 'n_classes', 'n_features', 'n_informative', 'n_jobs','n_samples', 'random_state',\n",
    "                 'scale', 'l1', 'l2','n_clusters', 'num', 'efficiency', 'complexity', 'local',\n",
    "                 'num*iter_job', 'num_class*flip*iter', 'feature * iter']]\n",
    "test_X = test[[ 'flip_y', 'max_iter', 'n_classes', 'n_features', 'n_informative', 'n_jobs',\n",
    "                 'n_samples', 'random_state', 'scale', 'l1', 'l2','n_clusters', 'num', 'efficiency', 'complexity', 'local',\n",
    "                 'num*iter_job', 'num_class*flip*iter', 'feature * iter']]\n",
    "train_y = train['time']\n",
    "test_y = test['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3693106114451201e-05 0.11487283936640692\n",
      "0.00796126106062299 0.1254320832159813\n",
      "0.006706676097157976 0.122270450568218\n",
      "0.0011624594171199233 0.11555510962135854\n",
      "0.004305042631167184 0.1162556661803873\n",
      "0.000515958085899282 0.12385763887677033\n"
     ]
    }
   ],
   "source": [
    "lgbm1 = lgbm.LGBMRegressor(random_state= 24,n_estimators=1800,learning_rate= 0.05,max_depth= 4, num_leaves = 31,min_child_samples= 15,\n",
    "                                reg_lambda=0.5).fit(train_X,train_y)\n",
    "print(mse(train_y,lgbm1.predict(train_X)),mse(test_y,lgbm1.predict(test_X)))\n",
    "lgbm2 = lgbm.LGBMRegressor(random_state= 48,n_estimators=500,learning_rate= 0.03,max_depth= 4, num_leaves = 31,min_child_samples= 20,\n",
    "                                reg_lambda=0.5).fit(train_X,train_y)\n",
    "print(mse(train_y,lgbm2.predict(train_X)),mse(test_y,lgbm2.predict(test_X)))\n",
    "lgbm3 = lgbm.LGBMRegressor(random_state= 48,n_estimators = 500,learning_rate= 0.03,max_depth= 5, num_leaves = 31,min_child_samples= 20,\n",
    "                                reg_lambda=0.5).fit(train_X,train_y)\n",
    "print(mse(train_y,lgbm3.predict(train_X)),mse(test_y,lgbm3.predict(test_X)))\n",
    "lgbm4 = lgbm.LGBMRegressor(random_state= 48,n_estimators = 900,learning_rate= 0.06,max_depth= 3, num_leaves = 31,min_child_samples= 20,\n",
    "                                reg_lambda=0.1).fit(train_X,train_y)\n",
    "print(mse(train_y,lgbm4.predict(train_X)),mse(test_y,lgbm4.predict(test_X)))\n",
    "lgbm5 = lgbm.LGBMRegressor(random_state= 100,n_estimators=700,learning_rate= 0.04,max_depth= 3, num_leaves = 31,min_child_samples= 20,\n",
    "                                reg_lambda=0.2).fit(train_X,train_y)\n",
    "print(mse(train_y,lgbm5.predict(train_X)),mse(test_y,lgbm5.predict(test_X)))\n",
    "lgbm6 = lgbm.LGBMRegressor(random_state= 35,n_estimators=500,learning_rate= 0.1,max_depth= 4, num_leaves = 31,min_child_samples= 20,\n",
    "                                reg_lambda=0.1).fit(train_X,train_y)\n",
    "print(mse(train_y,lgbm6.predict(train_X)),mse(test_y,lgbm6.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[469:]\n",
    "test_X = test[[ 'flip_y', 'max_iter', 'n_classes', 'n_features', 'n_informative', 'n_jobs',\n",
    "                 'n_samples', 'random_state', 'scale', 'l1', 'l2','n_clusters', 'num', 'efficiency', 'complexity', 'local',\n",
    "                 'num*iter_job', 'num_class*flip*iter', 'feature * iter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (lgbm1.predict(test_X)+lgbm2.predict(test_X)+lgbm3.predict(test_X)+lgbm4.predict(test_X)+lgbm5.predict(test_X)+lgbm6.predict(test_X))/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.exp(y)\n",
    "final = pd.DataFrame(y)\n",
    "final = final.reset_index()\n",
    "final.columns = ['id','time']\n",
    "final.to_csv('submission.csv',index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
